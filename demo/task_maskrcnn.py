import mmcv
import torch
import os
import time
import numpy as np
from mmdet.apis import init_detector, inference_detector
from mmengine.structures import InstanceData
from mmdet.structures import DetDataSample
from mmdet.registry import VISUALIZERS

# ------------------------------
# é…ç½®éƒ¨åˆ†
# ------------------------------
config_path = 'configs/mask_rcnn/mask-rcnn_r50_fpn_1x_coco.py'
checkpoint_path = 'work_dirs/mask-rcnn_r50_fpn_1x_voc/good_chekpoint.pth'
input_dir = 'data/new_pic'
output_dir = 'data/mask_rcnn/result'
os.makedirs(output_dir, exist_ok=True)
score_threshold = 0.3
max_image_size = 1600

# COCO 80ç±»åˆ«
COCO_CLASSES = (
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
    'hair drier', 'toothbrush'
)

# VOC 20ç±»åˆ«ï¼ˆå®Œæ•´åˆ—è¡¨ï¼‰
VOC_CLASSES = [
    'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',
    'bus', 'car', 'cat', 'chair', 'cow',
    'diningtable', 'dog', 'horse', 'motorbike', 'person',
    'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'
]

# COCOåˆ°VOCçš„ç±»åˆ«æ˜ å°„ï¼ˆå®Œæ•´æ˜ å°„ï¼‰
COCO_TO_VOC = {
    # æ ¼å¼: COCOç´¢å¼• : VOCç´¢å¼•
    # äº¤é€šå·¥å…·ç±»
    0: 14,   # person -> person
    1: 1,    # bicycle -> bicycle
    2: 6,    # car -> car
    3: 13,   # motorcycle -> motorbike
    4: 0,    # airplane -> aeroplane
    5: 5,    # bus -> bus
    6: 18,   # train -> train
    7: 6,    # truck -> car (VOCæ— truck)
    8: 3,    # boat -> boat
    # åŠ¨ç‰©ç±»
    14: 2,   # bird -> bird
    15: 7,   # cat -> cat
    16: 11,  # dog -> dog
    17: 12,  # horse -> horse
    18: 16,  # sheep -> sheep
    19: 9,   # cow -> cow
    # å®¶å…·ç±»
    56: 8,   # chair -> chair
    57: 17,  # couch -> sofa
    59: 15,  # potted plant -> pottedplant
    60: 10,  # dining table -> diningtable
    62: 19,  # tv -> tvmonitor
    # å…¶ä»–
    9: 4,    # traffic light -> bottle (æ— å¯¹åº”)
    43: 4,   # bottle -> bottle
}
# ------------------------------
# æ¨¡å‹åˆå§‹åŒ–
# ------------------------------
def init_model():
    print(f"[{time.strftime('%H:%M:%S')}] âš™ï¸ åˆå§‹åŒ–æ¨¡å‹...")
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    model = init_detector(config_path, checkpoint_path, device=device)
    model.dataset_meta = {'classes': COCO_CLASSES}
    return model

# ------------------------------
# ç»“æœå¤„ç†
# ------------------------------
def process_results(results, img_shape):
    h, w = img_shape[:2]
    pred = results.pred_instances
    
    # åæ ‡ä¿®æ­£
    bboxes = pred.bboxes.clone()
    bboxes[:, 0::2] = torch.clamp(bboxes[:, 0::2], 0, w)
    bboxes[:, 1::2] = torch.clamp(bboxes[:, 1::2], 0, h)
    
    # ç±»åˆ«æ˜ å°„
    valid_mask = torch.zeros_like(pred.labels, dtype=torch.bool)
    converted_labels = torch.zeros_like(pred.labels)
    
    for i, label in enumerate(pred.labels):
        coco_idx = int(label)
        if coco_idx in COCO_TO_VOC:
            valid_mask[i] = True
            converted_labels[i] = COCO_TO_VOC[coco_idx]
    
    # ç»¼åˆè¿‡æ»¤
    keep_mask = (pred.scores > score_threshold) & valid_mask
    
    filtered = DetDataSample()
    filtered.pred_instances = InstanceData(
        bboxes=bboxes[keep_mask],
        scores=pred.scores[keep_mask],
        labels=converted_labels[keep_mask],
        masks=pred.masks[keep_mask] if hasattr(pred, 'masks') else None
    )
    return filtered
# ------------------------------
# å¯è§†åŒ–å·¥å…·ï¼ˆå…³é”®ä¿®æ”¹ï¼‰
# ------------------------------
class ResultVisualizer:
    def __init__(self, model):
        self.visualizer = VISUALIZERS.build(model.cfg.visualizer)
        self.visualizer.dataset_meta = {'classes': VOC_CLASSES}
    
    def draw_detection(self, img, result, out_path):
        """ä»…ç»˜åˆ¶æ£€æµ‹æ¡†ï¼ˆå…³é”®ä¿®æ”¹ï¼šç¡®ä¿ä¸æ˜¾ç¤ºæ©è†œï¼‰"""
        # åˆ›å»ºä¸åŒ…å«æ©è†œçš„ä¸´æ—¶ç»“æœ
        det_result = DetDataSample()
        det_result.pred_instances = InstanceData(
            bboxes=result.pred_instances.bboxes,
            scores=result.pred_instances.scores,
            labels=result.pred_instances.labels
        )
        
        # æ–°ç‰ˆæœ¬MMDetectionä½¿ç”¨draw_instances
        if hasattr(self.visualizer, 'draw_instances'):
            self.visualizer.draw_instances(
                image=img,
                instances=det_result.pred_instances,
                draw_heatmap=False,
                show=False,
                out_file=out_path
            )
        # æ—§ç‰ˆæœ¬å…¼å®¹
        else:
            self.visualizer.add_datasample(
                'det',
                img,
                data_sample=det_result,
                draw_gt=False,
                show=False,
                out_file=out_path
            )
    
    def draw_segmentation(self, img, result, out_path):
        """ç»˜åˆ¶æ£€æµ‹æ¡†å’Œæ©è†œ"""
        if not hasattr(result.pred_instances, 'masks'):
            print("è­¦å‘Šï¼šå½“å‰ç»“æœä¸åŒ…å«æ©è†œä¿¡æ¯")
            return
            
        # æ–°ç‰ˆæœ¬MMDetectionä½¿ç”¨draw_instances
        if hasattr(self.visualizer, 'draw_instances'):
            self.visualizer.draw_instances(
                image=img,
                instances=result.pred_instances,
                draw_heatmap=False,
                show=False,
                out_file=out_path
            )
        # æ—§ç‰ˆæœ¬å…¼å®¹
        else:
            self.visualizer.add_datasample(
                'seg',
                img,
                data_sample=result,
                draw_gt=False,
                show=False,
                out_file=out_path
            )

# ------------------------------
# ä¿å­˜ç»“æœï¼ˆå…³é”®ä¿®æ”¹ï¼‰
# ------------------------------
def save_results(result, base_path, img):
    """ä¿å­˜ä¸¤ç§ç»“æœï¼šç›®æ ‡æ£€æµ‹å’Œå®ä¾‹åˆ†å‰²"""
    visualizer = ResultVisualizer(model)
    
    # 1. ä¿å­˜ç›®æ ‡æ£€æµ‹ç»“æœï¼ˆç¡®ä¿ä¸åŒ…å«æ©è†œï¼‰
    det_txt_path = f"{base_path}.txt"
    det_img_path = f"{base_path}_det.jpg"
    
    with open(det_txt_path, 'w') as f:
        for bbox, score, label in zip(
            result.pred_instances.bboxes,
            result.pred_instances.scores,
            result.pred_instances.labels
        ):
            label_idx = int(label)
            class_name = VOC_CLASSES[label_idx] if label_idx < len(VOC_CLASSES) else 'unknown'
            f.write(f"{class_name} {score:.4f} {int(bbox[0])} {int(bbox[1])} {int(bbox[2])} {int(bbox[3])}\n")
    
    # å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ä»…åŒ…å«è¾¹ç•Œæ¡†çš„å¯è§†åŒ–æ–¹æ³•
    visualizer.draw_detection(img, result, det_img_path)
    
    # 2. ä¿å­˜å®ä¾‹åˆ†å‰²ç»“æœï¼ˆå¦‚æœå­˜åœ¨æ©è†œï¼‰
    if hasattr(result.pred_instances, 'masks') and result.pred_instances.masks is not None:
        seg_txt_path = f"{base_path}_seg.txt"
        seg_img_path = f"{base_path}_seg.jpg"
        
        with open(seg_txt_path, 'w') as f:
            for i, (bbox, score, label, mask) in enumerate(zip(
                result.pred_instances.bboxes,
                result.pred_instances.scores,
                result.pred_instances.labels,
                result.pred_instances.masks
            )):
                label_idx = int(label)
                class_name = VOC_CLASSES[label_idx] if label_idx < len(VOC_CLASSES) else 'unknown'
                f.write(f"Object {i}:\n")
                f.write(f"  Class: {class_name}\n")
                f.write(f"  Score: {score:.4f}\n")
                f.write(f"  BBox: {bbox.int().tolist()}\n\n")
        
        visualizer.draw_segmentation(img, result, seg_img_path)
        
# ------------------------------
# ä¸»æµç¨‹
# ------------------------------
def main():
    print(f"[{time.strftime('%H:%M:%S')}] ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†å›¾ç‰‡")
    
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        global model
        model = init_model()
        
        # å¤„ç†æ¯å¼ å›¾ç‰‡
        for img_file in os.listdir(input_dir):
            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue
                
            start_time = time.time()
            img_path = os.path.join(input_dir, img_file)
            base_name = os.path.splitext(img_file)[0]
            base_path = os.path.join(output_dir, base_name)
            
            print(f"\n[å¤„ç†] {img_file}")
            
            # è¯»å–å’Œé¢„å¤„ç†å›¾åƒ
            img = mmcv.imread(img_path, channel_order='rgb')
            if max(img.shape[:2]) > max_image_size:
                scale = max_image_size / max(img.shape[:2])
                img = mmcv.imrescale(img, scale=scale)
            
            # æ¨ç†å’Œå¤„ç†ç»“æœ
            result = inference_detector(model, img)
            processed_result = process_results(result, img.shape)
            
            # ä¿å­˜ç»“æœ
            save_results(processed_result, base_path, img)
            
            print(f"[å®Œæˆ] è€—æ—¶: {time.time()-start_time:.2f}s")
            
    except Exception as e:
        print(f"\n[é”™è¯¯] {str(e)}")
    finally:
        print(f"\n[ç»“æŸ] æ‰€æœ‰å¤„ç†å®Œæˆ")

if __name__ == '__main__':
    main()
import mmcv
import torch
import os
import time
import numpy as np
from mmdet.apis import init_detector, inference_detector
from mmengine.structures import InstanceData
from mmdet.structures import DetDataSample
from mmdet.registry import VISUALIZERS

# ------------------------------
# é…ç½®éƒ¨åˆ†
# ------------------------------
config_path = 'configs/sparse_rcnn/sparse-rcnn_r50_fpn_1x_coco.py'
checkpoint_path = 'work_dirs/sparse-rcnn_r50_fpn_1x_voc/good_checkpoint.pth'
input_dir = 'data/new_pic'
output_dir = 'data/sparse_rcnn/result'
os.makedirs(output_dir, exist_ok=True)
score_threshold = 0.3
max_image_size = 1600

# COCO 80ç±»åˆ«
COCO_CLASSES = (
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
    'hair drier', 'toothbrush'
)

# ------------------------------
# æ¨¡å‹åˆå§‹åŒ–
# ------------------------------
def init_model():
    print(f"[{time.strftime('%H:%M:%S')}] âš™ï¸ åˆå§‹åŒ–æ¨¡å‹...")
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    model = init_detector(config_path, checkpoint_path, device=device)
    model.dataset_meta = {'classes': COCO_CLASSES}
    return model

# ------------------------------
# ç»“æœå¤„ç† (é€‚é…SparseRCNNç‰¹æ€§)
# ------------------------------
def process_results(results, img_shape):
    """å¤„ç†SparseRCNNçš„è¾“å‡ºç»“æœ"""
    h, w = img_shape[:2]
    pred = results.pred_instances
    
    # SparseRCNNç‰¹æœ‰å¤„ç†ï¼šç¡®ä¿proposalæ•°é‡ä¸è¶…è¿‡è®¾å®šå€¼
    if len(pred) > num_proposals:
        keep = pred.scores.topk(num_proposals)[1]
        pred = pred[keep]
    
    # åæ ‡ä¿®æ­£
    bboxes = pred.bboxes.clone()
    bboxes[:, 0::2] = torch.clamp(bboxes[:, 0::2], 0, w)
    bboxes[:, 1::2] = torch.clamp(bboxes[:, 1::2], 0, h)
    
    # è¿‡æ»¤ä½åˆ†æ£€æµ‹
    keep_mask = pred.scores > score_threshold
    
    filtered = DetDataSample()
    filtered.pred_instances = InstanceData(
        bboxes=bboxes[keep_mask],
        scores=pred.scores[keep_mask],
        labels=pred.labels[keep_mask],
        masks=pred.masks[keep_mask] if hasattr(pred, 'masks') else None
    )
    return filtered

# ------------------------------
# å¯è§†åŒ–å·¥å…· (é€‚é…SparseRCNN)
# ------------------------------
class SparseRCNNVisualizer:
    def __init__(self, model):
        self.visualizer = VISUALIZERS.build(model.cfg.visualizer)
        self.visualizer.dataset_meta = model.dataset_meta
    
    def draw_results(self, img, result, out_path):
        """ç»˜åˆ¶æ£€æµ‹å’Œåˆ†å‰²ç»“æœ"""
        # æ–°ç‰ˆæœ¬MMDetectionä½¿ç”¨draw_instances
        if hasattr(self.visualizer, 'draw_instances'):
            self.visualizer.draw_instances(
                image=img,
                instances=result.pred_instances,
                draw_heatmap=False,
                show=False,
                out_file=out_path
            )
        # æ—§ç‰ˆæœ¬å…¼å®¹
        else:
            self.visualizer.add_datasample(
                'result',
                img,
                data_sample=result,
                draw_gt=False,
                show=False,
                out_file=out_path
            )

# ------------------------------
# ä¿å­˜ç»“æœ (é€‚é…SparseRCNN)
# ------------------------------
def save_results(result, base_path, img):
    """ä¿å­˜æ£€æµ‹å’Œåˆ†å‰²ç»“æœ"""
    visualizer = SparseRCNNVisualizer(model)
    
    # ä¿å­˜å¯è§†åŒ–ç»“æœ
    vis_path = f"{base_path}_result.jpg"
    visualizer.draw_results(img, result, vis_path)
    
    # ä¿å­˜æ£€æµ‹ç»“æœæ–‡æœ¬
    txt_path = f"{base_path}.txt"
    with open(txt_path, 'w') as f:
        for i, (bbox, score, label) in enumerate(zip(
            result.pred_instances.bboxes,
            result.pred_instances.scores,
            result.pred_instances.labels
        )):
            class_name = COCO_CLASSES[int(label)] if int(label) < len(COCO_CLASSES) else 'unknown'
            f.write(f"Object {i}:\n")
            f.write(f"  Class: {class_name}\n")
            f.write(f"  Score: {score:.4f}\n")
            f.write(f"  BBox: {bbox.int().tolist()}\n\n")
    
    # å¦‚æœæœ‰æ©è†œï¼Œä¿å­˜æ©è†œä¿¡æ¯
    if hasattr(result.pred_instances, 'masks') and result.pred_instances.masks is not None:
        mask_path = f"{base_path}_mask.npy"
        np.save(mask_path, result.pred_instances.masks.cpu().numpy())

# ------------------------------
# ä¸»æµç¨‹
# ------------------------------
def main():
    print(f"[{time.strftime('%H:%M:%S')}] ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç†å›¾ç‰‡")
    
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        global model, num_proposals
        model = init_model()
        num_proposals = model.test_cfg.rcnn.max_per_img
        
        # å¤„ç†æ¯å¼ å›¾ç‰‡
        for img_file in os.listdir(input_dir):
            if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                continue
                
            start_time = time.time()
            img_path = os.path.join(input_dir, img_file)
            base_name = os.path.splitext(img_file)[0]
            base_path = os.path.join(output_dir, base_name)
            
            print(f"\n[å¤„ç†] {img_file}")
            
            # è¯»å–å’Œé¢„å¤„ç†å›¾åƒ
            img = mmcv.imread(img_path, channel_order='rgb')
            if max(img.shape[:2]) > max_image_size:
                scale = max_image_size / max(img.shape[:2])
                img = mmcv.imrescale(img, scale=scale)
            
            # æ¨ç†å’Œå¤„ç†ç»“æœ
            result = inference_detector(model, img)
            processed_result = process_results(result, img.shape)
            
            # ä¿å­˜ç»“æœ
            save_results(processed_result, base_path, img)
            
            print(f"[å®Œæˆ] è€—æ—¶: {time.time()-start_time:.2f}s")
            
    except Exception as e:
        print(f"\n[é”™è¯¯] {str(e)}")
    finally:
        print(f"\n[ç»“æŸ] æ‰€æœ‰å¤„ç†å®Œæˆ")

if __name__ == '__main__':
    main()